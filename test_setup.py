"""
Intel GPU Test Script for Xilo AI Tutor
Tests PyTorch XPU functionality and Intel GPU detection
"""

import sys
import torch
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_intel_gpu():
    """Test Intel GPU availability and functionality"""
    print("ğŸ” Testing Intel GPU Setup for Xilo AI Tutor")
    print("=" * 50)
    
    # Test basic PyTorch installation
    print(f"âœ… PyTorch Version: {torch.__version__}")
    
    # Test Intel XPU availability
    try:
        import intel_extension_for_pytorch as ipex
        print(f"âœ… Intel Extension for PyTorch: {ipex.__version__}")
        
        if hasattr(torch, 'xpu'):
            print("âœ… PyTorch XPU support available")
            
            if torch.xpu.is_available():
                print("ğŸš€ Intel XPU is available!")
                
                # Get device count and info
                device_count = torch.xpu.device_count()
                print(f"ğŸ“Š Number of XPU devices: {device_count}")
                
                if device_count > 0:
                    current_device = torch.xpu.current_device()
                    device_name = torch.xpu.get_device_name(current_device)
                    print(f"ğŸ¯ Current device: {current_device}")
                    print(f"ğŸ’» GPU Name: {device_name}")
                    
                    # Test tensor operations
                    print("\nğŸ§ª Testing tensor operations...")
                    device = torch.device(f"xpu:{current_device}")
                    
                    # Create test tensors
                    x = torch.randn(1000, 1000, device=device)
                    y = torch.randn(1000, 1000, device=device)
                    
                    # Perform matrix multiplication
                    result = torch.mm(x, y)
                    print(f"âœ… Matrix multiplication successful: {result.shape}")
                    
                    # Test memory info
                    memory_allocated = torch.xpu.memory_allocated(current_device)
                    memory_cached = torch.xpu.memory_reserved(current_device)
                    
                    print(f"ğŸ“ˆ Memory allocated: {memory_allocated / 1024**2:.2f} MB")
                    print(f"ğŸ“ˆ Memory cached: {memory_cached / 1024**2:.2f} MB")
                    
                    # Clear memory
                    del x, y, result
                    torch.xpu.empty_cache()
                    print("ğŸ§¹ Memory cleared")
                    
                    print("\nğŸ‰ Intel GPU test completed successfully!")
                    print("ğŸš€ Your Battlemage GPU with XMX engines is ready for Xilo AI Tutor!")
                    
                    return True
                    
                else:
                    print("âŒ No XPU devices found")
                    return False
                    
            else:
                print("âŒ Intel XPU not available")
                return False
                
        else:
            print("âŒ PyTorch XPU support not available")
            return False
            
    except ImportError as e:
        print(f"âŒ Intel Extension for PyTorch not available: {e}")
        return False
    except Exception as e:
        print(f"âŒ Error testing Intel GPU: {e}")
        return False

def test_model_compatibility():
    """Test model loading compatibility"""
    print("\nğŸ¤– Testing Model Compatibility")
    print("=" * 30)
    
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        print("âœ… Transformers library available")
        
        # Test tokenizer loading (lightweight)
        print("ğŸ“ Testing tokenizer loading...")
        tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-medium")
        print("âœ… Tokenizer loaded successfully")
        
        print("ğŸ¯ Model compatibility test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Model compatibility test failed: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ“ Xilo AI Tutor - Intel GPU Test")
    print("Optimized for Intel Battlemage with XMX engines")
    print()
    
    gpu_test = test_intel_gpu()
    model_test = test_model_compatibility()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š TEST SUMMARY")
    print("=" * 50)
    print(f"Intel GPU Support: {'âœ… PASS' if gpu_test else 'âŒ FAIL'}")
    print(f"Model Compatibility: {'âœ… PASS' if model_test else 'âŒ FAIL'}")
    
    if gpu_test and model_test:
        print("\nğŸ‰ All tests passed! Xilo AI Tutor is ready to run on your Intel GPU!")
        print("ğŸš€ Start the application with: python app.py")
    else:
        print("\nâš ï¸  Some tests failed. Check the output above for details.")
        if not gpu_test:
            print("ğŸ’¡ GPU issues may be due to driver installation or hardware compatibility.")
        if not model_test:
            print("ğŸ’¡ Model issues may be due to missing dependencies.")
    
    print("\nğŸ”§ System Information:")
    print(f"   Python: {sys.version}")
    print(f"   PyTorch: {torch.__version__}")
    try:
        import intel_extension_for_pytorch as ipex
        print(f"   Intel Extension: {ipex.__version__}")
    except ImportError:
        print("   Intel Extension: Not installed")
